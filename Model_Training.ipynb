{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4f34c89-01d9-44b7-969c-6b587dc163ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'MaxT', 'MinT', 'WindSpeed', 'Humidity', 'Precipitation'], dtype='object')\n",
      "                  Date      MaxT      MinT  WindSpeed  Humidity  \\\n",
      "0  2006-01-08 00:00:00  0.291188  0.397849   0.148649  0.614551   \n",
      "1  2006-01-09 00:00:00  0.314176  0.354839   0.148649  0.571207   \n",
      "2  2006-01-10 00:00:00  0.306513  0.360215   0.162162  0.537152   \n",
      "3  2006-01-11 00:00:00  0.302682  0.344086   0.135135  0.595975   \n",
      "4  2006-01-12 00:00:00  0.295019  0.327957   0.216216  0.603715   \n",
      "\n",
      "   Precipitation      AvgT  heat_index  \n",
      "0            0.0  0.269129    0.285281  \n",
      "1            0.0  0.263852    0.272804  \n",
      "2            0.0  0.261214    0.264623  \n",
      "3            0.0  0.250660    0.262485  \n",
      "4            0.0  0.237467    0.249496  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the CSV file\n",
    "data = pd.read_csv('C:/Users/ploke/Music/Weather_Data.csv')\n",
    "\n",
    "# Strip any leading/trailing whitespace characters from column names\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Print column names to verify\n",
    "print(data.columns)\n",
    "\n",
    "# Check if the required columns exist\n",
    "required_columns = ['MaxT', 'MinT', 'WindSpeed', 'Humidity']\n",
    "if all(column in data.columns for column in required_columns):\n",
    "    # Fill missing values (forward fill)\n",
    "    data.ffill(inplace=True)\n",
    "    \n",
    "    # Calculate average temperature\n",
    "    data['AvgT'] = (data['MaxT'] + data['MinT']) / 2\n",
    "    \n",
    "    # Feature engineering (example: compute a heat index-like feature)\n",
    "    data['heat_index'] = 0.5 * (data['AvgT'] + 61.0 + ((data['AvgT'] - 68.0) * 1.2) + (data['Humidity'] * 0.094))\n",
    "    \n",
    "    # Normalize the data\n",
    "    scaler = MinMaxScaler()\n",
    "    data[['MaxT', 'MinT', 'WindSpeed', 'Humidity', 'AvgT', 'heat_index']] = scaler.fit_transform(data[['MaxT', 'MinT', 'WindSpeed', 'Humidity', 'AvgT', 'heat_index']])\n",
    "    \n",
    "    print(data.head())\n",
    "else:\n",
    "    print(\"One or more required columns ('MaxT', 'MinT', 'WindSpeed', 'Humidity') are missing in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d8746c4-b201-4282-9fda-2f4bad05aabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'MaxT', 'MinT', 'WindSpeed', 'Humidity', 'Precipitation'], dtype='object')\n",
      "Model Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load the CSV file\n",
    "data = pd.read_csv('C:/Users/ploke/Music/Weather_Data.csv')\n",
    "\n",
    "# Strip any leading/trailing whitespace characters from column names\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Print column names to verify\n",
    "print(data.columns)\n",
    "\n",
    "# Check if the required columns exist\n",
    "required_columns = ['MaxT', 'MinT', 'WindSpeed', 'Humidity']\n",
    "if all(column in data.columns for column in required_columns):\n",
    "    # Fill missing values (forward fill)\n",
    "    data.ffill(inplace=True)\n",
    "    \n",
    "    # Calculate average temperature\n",
    "    data['AvgT'] = (data['MaxT'] + data['MinT']) / 2\n",
    "    \n",
    "    # Feature engineering (example: compute a heat index-like feature)\n",
    "    data['heat_index'] = 0.5 * (data['AvgT'] + 61.0 + ((data['AvgT'] - 68.0) * 1.2) + (data['Humidity'] * 0.094))\n",
    "    \n",
    "    # Normalize the data\n",
    "    scaler = MinMaxScaler()\n",
    "    data[['MaxT', 'MinT', 'WindSpeed', 'Humidity', 'AvgT', 'heat_index']] = scaler.fit_transform(data[['MaxT', 'MinT', 'WindSpeed', 'Humidity', 'AvgT', 'heat_index']])\n",
    "    \n",
    "    # Define the threshold for a heat wave (example: AvgT > 30°C)\n",
    "    threshold = 30\n",
    "    \n",
    "    # Define the target variable\n",
    "    data['heat_wave'] = (data['AvgT'] > threshold).astype(int)\n",
    "    \n",
    "    # Split the data into features and target\n",
    "    X = data[['MaxT', 'MinT', 'WindSpeed', 'Humidity', 'AvgT', 'heat_index']]\n",
    "    y = data['heat_wave']\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train a Random Forest Classifier\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    print(f\"Model Accuracy: {accuracy:.2f}\")\n",
    "else:\n",
    "    print(\"One or more required columns ('MaxT', 'MinT', 'WindSpeed', 'Humidity') are missing in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6edba04-b7ab-4a21-a4d7-e6eb4dc16e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'MaxT', 'MinT', 'WindSpeed', 'Humidity', 'Precipitation'], dtype='object')\n",
      "heat_wave\n",
      "0    6236\n",
      "Name: count, dtype: int64\n",
      "0    1248\n",
      "Name: count, dtype: int64\n",
      "Accuracy: 1.0\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the CSV file\n",
    "data = pd.read_csv('C:/Users/ploke/Music/Weather_Data.csv')\n",
    "\n",
    "# Strip any leading/trailing whitespace characters from column names\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Print column names to verify\n",
    "print(data.columns)\n",
    "\n",
    "# Check if the required columns exist\n",
    "required_columns = ['MaxT', 'MinT', 'WindSpeed', 'Humidity']\n",
    "if all(column in data.columns for column in required_columns):\n",
    "    # Fill missing values (forward fill)\n",
    "    data.ffill(inplace=True)\n",
    "    \n",
    "    # Calculate average temperature\n",
    "    data['AvgT'] = (data['MaxT'] + data['MinT']) / 2\n",
    "    \n",
    "    # Feature engineering (example: compute a heat index-like feature)\n",
    "    data['heat_index'] = 0.5 * (data['AvgT'] + 61.0 + ((data['AvgT'] - 68.0) * 1.2) + (data['Humidity'] * 0.094))\n",
    "    \n",
    "    # Normalize the data\n",
    "    scaler = MinMaxScaler()\n",
    "    data[['MaxT', 'MinT', 'WindSpeed', 'Humidity', 'AvgT', 'heat_index']] = scaler.fit_transform(data[['MaxT', 'MinT', 'WindSpeed', 'Humidity', 'AvgT', 'heat_index']])\n",
    "    \n",
    "    # Define the threshold for a heat wave (example: AvgT > 30°C)\n",
    "    threshold = 30\n",
    "    \n",
    "    # Define the target variable\n",
    "    data['heat_wave'] = (data['AvgT'] > threshold).astype(int)\n",
    "    \n",
    "    # Check the distribution of the target variable\n",
    "    print(data['heat_wave'].value_counts())\n",
    "    \n",
    "    # Split the data into features and target\n",
    "    X = data[['MaxT', 'MinT', 'WindSpeed', 'Humidity', 'AvgT', 'heat_index']]\n",
    "    y = data['heat_wave']\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train a Random Forest Classifier\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Check the distribution of the predictions\n",
    "    print(pd.Series(y_pred).value_counts())\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "\n",
    "else:\n",
    "    print(\"One or more required columns ('MaxT', 'MinT', 'WindSpeed', 'Humidity') are missing in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "045094bf-1cd8-44d9-a797-bf339f883b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heat_wave\n",
      "0    6236\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define a new, lower threshold for a heat wave\n",
    "threshold = 15  # Try a further lower threshold\n",
    "\n",
    "# Apply the new threshold to create the 'heat_wave' target variable\n",
    "data['heat_wave'] = (data['AvgT'] > threshold).astype(int)\n",
    "\n",
    "# Check the distribution of the target variable\n",
    "print(data['heat_wave'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70c93806-1dd6-46bc-9559-bdc96c7e7c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 9)\n",
      "Empty DataFrame\n",
      "Columns: [Date, MaxT, MinT, WindSpeed, Humidity, AvgT, heat_wave]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check for instances where 'AvgT' exceeds the threshold\n",
    "print(data[data['AvgT'] > threshold].shape)  # Should be non-zero\n",
    "print(data[data['AvgT'] > threshold][['Date', 'MaxT', 'MinT', 'WindSpeed', 'Humidity', 'AvgT', 'heat_wave']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1524cd70-6b81-4b9a-b5dc-bb512d0099e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'MaxT', 'MinT', 'WindSpeed', 'Humidity', 'Precipitation'], dtype='object')\n",
      "count    6236.000000\n",
      "mean        0.448121\n",
      "std         0.153598\n",
      "min         0.000000\n",
      "25%         0.329815\n",
      "50%         0.448549\n",
      "75%         0.548813\n",
      "max         1.000000\n",
      "Name: AvgT, dtype: float64\n",
      "heat_wave\n",
      "0    6055\n",
      "1     181\n",
      "Name: count, dtype: int64\n",
      "0    1215\n",
      "1      33\n",
      "Name: count, dtype: int64\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the CSV file\n",
    "data = pd.read_csv('C:/Users/ploke/Music/Weather_Data.csv')\n",
    "\n",
    "# Strip any leading/trailing whitespace characters from column names\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Print column names to verify\n",
    "print(data.columns)\n",
    "\n",
    "# Check if the required columns exist\n",
    "required_columns = ['MaxT', 'MinT', 'WindSpeed', 'Humidity']\n",
    "if all(column in data.columns for column in required_columns):\n",
    "    # Fill missing values (forward fill)\n",
    "    data.ffill(inplace=True)\n",
    "    \n",
    "    # Calculate average temperature\n",
    "    data['AvgT'] = (data['MaxT'] + data['MinT']) / 2\n",
    "    \n",
    "    # Feature engineering (example: compute a heat index-like feature)\n",
    "    data['heat_index'] = 0.5 * (data['AvgT'] + 61.0 + ((data['AvgT'] - 68.0) * 1.2) + (data['Humidity'] * 0.094))\n",
    "    \n",
    "    # Normalize the data\n",
    "    scaler = MinMaxScaler()\n",
    "    data[['MaxT', 'MinT', 'WindSpeed', 'Humidity', 'AvgT', 'heat_index']] = scaler.fit_transform(data[['MaxT', 'MinT', 'WindSpeed', 'Humidity', 'AvgT', 'heat_index']])\n",
    "    \n",
    "    # Explore the distribution of AvgT to choose an appropriate threshold\n",
    "    print(data['AvgT'].describe())\n",
    "    \n",
    "    # Define the threshold for a heat wave (example: AvgT > 0.75, since data is normalized)\n",
    "    threshold = 0.75\n",
    "    \n",
    "    # Define the target variable\n",
    "    data['heat_wave'] = (data['AvgT'] > threshold).astype(int)\n",
    "    \n",
    "    # Check the distribution of the target variable\n",
    "    print(data['heat_wave'].value_counts())\n",
    "    \n",
    "    # Split the data into features and target\n",
    "    X = data[['MaxT', 'MinT', 'WindSpeed', 'Humidity', 'AvgT', 'heat_index']]\n",
    "    y = data['heat_wave']\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train a Random Forest Classifier\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Check the distribution of the predictions\n",
    "    print(pd.Series(y_pred).value_counts())\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "\n",
    "else:\n",
    "    print(\"One or more required columns ('MaxT', 'MinT', 'WindSpeed', 'Humidity') are missing in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a4193c4-3106-46c2-a9d8-21a0b7f84dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MaxT', 'MinT', 'WindSpeed', 'Humidity'], dtype='object')\n",
      "Scaler saved as 'scaler.pkl'\n",
      "count    6236.000000\n",
      "mean        0.448121\n",
      "std         0.153598\n",
      "min         0.000000\n",
      "25%         0.329815\n",
      "50%         0.448549\n",
      "75%         0.548813\n",
      "max         1.000000\n",
      "Name: AvgT, dtype: float64\n",
      "heat_wave\n",
      "0    6055\n",
      "1     181\n",
      "Name: count, dtype: int64\n",
      "0    1215\n",
      "1      33\n",
      "Name: count, dtype: int64\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "Model saved as 'heat_wave_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "\n",
    "# Load the CSV file\n",
    "data = pd.read_csv('C:/Users/ploke/Music/Weather_Data.csv')\n",
    "\n",
    "# Strip any leading/trailing whitespace characters from column names\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Print column names to verify\n",
    "print(data.columns)\n",
    "\n",
    "# Check if the required columns exist\n",
    "required_columns = ['MaxT', 'MinT', 'WindSpeed', 'Humidity']\n",
    "if all(column in data.columns for column in required_columns):\n",
    "    # Fill missing values (forward fill)\n",
    "    data.ffill(inplace=True)\n",
    "    \n",
    "    # Calculate average temperature\n",
    "    data['AvgT'] = (data['MaxT'] + data['MinT']) / 2\n",
    "    \n",
    "    # Feature engineering (example: compute a heat index-like feature)\n",
    "    data['heat_index'] = 0.5 * (data['AvgT'] + 61.0 + ((data['AvgT'] - 68.0) * 1.2) + (data['Humidity'] * 0.094))\n",
    "    \n",
    "    # Normalize the data\n",
    "    scaler = MinMaxScaler()\n",
    "    data[['MaxT', 'MinT', 'WindSpeed', 'Humidity', 'AvgT', 'heat_index']] = scaler.fit_transform(data[['MaxT', 'MinT', 'WindSpeed', 'Humidity', 'AvgT', 'heat_index']])\n",
    "    \n",
    "    # Save the scaler\n",
    "    joblib.dump(scaler, 'scaler.pkl')\n",
    "    print(\"Scaler saved as 'scaler.pkl'\")\n",
    "    \n",
    "    # Explore the distribution of AvgT to choose an appropriate threshold\n",
    "    print(data['AvgT'].describe())\n",
    "    \n",
    "    # Define the threshold for a heat wave (example: AvgT > 0.75, since data is normalized)\n",
    "    threshold = 0.75\n",
    "    \n",
    "    # Define the target variable\n",
    "    data['heat_wave'] = (data['AvgT'] > threshold).astype(int)\n",
    "    \n",
    "    # Check the distribution of the target variable\n",
    "    print(data['heat_wave'].value_counts())\n",
    "    \n",
    "    # Split the data into features and target\n",
    "    X = data[['MaxT', 'MinT', 'WindSpeed', 'Humidity', 'AvgT', 'heat_index']]\n",
    "    y = data['heat_wave']\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train a Random Forest Classifier\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Check the distribution of the predictions\n",
    "    print(pd.Series(y_pred).value_counts())\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    \n",
    "    # Save the trained model\n",
    "    joblib.dump(model, 'heat_wave_model.pkl')\n",
    "    print(\"Model saved as 'heat_wave_model.pkl'\")\n",
    "else:\n",
    "    print(\"One or more required columns ('MaxT', 'MinT', 'WindSpeed', 'Humidity') are missing in the dataset.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
